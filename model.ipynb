{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return: depth scaling factor (d), width scaling factor (w), resolution scaling factor (r)\n",
    "\"\"\"\n",
    "def params(version):\n",
    "    if version == 'n':\n",
    "        return 1/3, 1/4, 2.0\n",
    "    elif version == 's':\n",
    "        return 1/3, 1/2, 2.0\n",
    "    elif version == 'm':\n",
    "        return 2/3, 3/4, 1.5\n",
    "    elif version == 'l':\n",
    "        return 1.0, 1.0, 1.0\n",
    "    elif version == 'x':\n",
    "        return 1.0, 1.25, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv\n",
    "![Conv](images/conv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0):\n",
      "Conv(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (act): SiLU(inplace=True)\n",
      ")\n",
      "torch.Size([1, 32, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "class Conv(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels (typically 3 for RGB images)\n",
    "    out_c: int, number of output channels (number of filters)\n",
    "    k: int, size of the kernel\n",
    "    s: int, stride of the kernel\n",
    "    p: int, padding of the kernel\n",
    "    g: int, number of groups\n",
    "    act: bool, whether to use activation function SiLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k = 3, s = 1, p = 1, g = 1, act = True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv2d: a convolutional layer\n",
    "        \"\"\"\n",
    "        in_c: int, number of input channels\n",
    "        out_c: int, number of output channels\n",
    "        k: int, size of the kernel\n",
    "        s: int, stride of the kernel\n",
    "        p: int, padding of the kernel\n",
    "        g: int, number of groups\n",
    "        bias: bool, whether to use bias\n",
    "        \"\"\"\n",
    "        self.conv = nn.Conv2d(in_c, out_c, k, s, p, bias = False, groups = g)\n",
    "\n",
    "        # BatchNorm2d: a normalization layer\n",
    "        \"\"\"\n",
    "        num_features: int, number of features\n",
    "        eps: float, a value added to the denominator for numerical stability\n",
    "        momentum: float, the value used for the running_mean and running_var computation\n",
    "        \"\"\"\n",
    "        self.bn = nn.BatchNorm2d(num_features = out_c, eps = 0.001, momentum = 0.03)\n",
    "\n",
    "        # SiLU: an activation function\n",
    "        \"\"\"\n",
    "        inplace: bool, whether to modify the input directly\n",
    "        \"\"\"\n",
    "        self.act = nn.SiLU(inplace = True) if act else nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv2d -> BatchNorm2d -> SiLU\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Convolutional Layer)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(0):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 3\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    kernel size: 3\n",
    "    stride: 2\n",
    "    padding: 1\n",
    "    groups: 1\n",
    "    activation: True\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 3\n",
    "    image height: 224\n",
    "    image width: 224\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True)(torch.randn(1, 3, 640, 640)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2f\n",
    "![Conv](images/c2f.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck\n",
    "![Bottleneck](images/bottleneck.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1):\n",
      "Bottleneck(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, shortcut=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv1: first convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv1 = Conv(in_c, out_c, k = 3, s = 1, p = 1)\n",
    "\n",
    "        # Conv: second convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv2 = Conv(out_c, out_c, k = 3, s = 1, p = 1)\n",
    "\n",
    "        # shortcut: a residual connection\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "\n",
    "        # Conv1\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # Conv2\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Shortcut\n",
    "        if self.shortcut:\n",
    "            x = x + x_in\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Bottleneck in the First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(1):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 64\n",
    "    image height: 224\n",
    "    image width: 224\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True)(torch.randn(1, int(64*w), 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2f Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2):\n",
      "C2f(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): ModuleList(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 64, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "class C2f(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    num_bottlenecks: int, number of bottlenecks\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, num_bottlenecks, shortcut = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mid_channels = out_c // 2\n",
    "        self.num_bottlenecks = num_bottlenecks\n",
    "\n",
    "        # Conv1: first convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv1 = Conv(in_c, out_c, k = 1, s = 1, p = 0)\n",
    "        \n",
    "        # Bottleneck Sequence\n",
    "        self.m = nn.ModuleList([Bottleneck(self.mid_channels, self.mid_channels, shortcut) for _ in range(num_bottlenecks)])\n",
    "\n",
    "        # Conv2: second convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv2 = Conv((num_bottlenecks + 2) * out_c // 2, out_c, k = 1, s = 1, p = 0)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        # Conv1\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # Split\n",
    "        x1, x2 = x[:,:x.shape[1]//2,:,:], x[:,x.shape[1]//2:,:,:]\n",
    "        outputs = [x1, x2]\n",
    "\n",
    "        # Bottleneck Sequence\n",
    "        for i in range(self.num_bottlenecks):\n",
    "            x1 = self.m[i](x1)\n",
    "            outputs.insert(0,x1)\n",
    "\n",
    "        # Concat\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "\n",
    "        # Conv2\n",
    "        out = self.conv2(outputs)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(2):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    output channels: 128 * width scaling factor (0.5)\n",
    "    number of bottlenecks: 3\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 64\n",
    "    image height: 224\n",
    "    image width: 224\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True)(torch.randn(1, int(128*w), 160, 160)).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
