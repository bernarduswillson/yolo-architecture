{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return: depth scaling factor (d), width scaling factor (w), resolution scaling factor (r)\n",
    "\"\"\"\n",
    "def params(version):\n",
    "    if version == 'n':\n",
    "        return 1/3, 1/4, 2.0\n",
    "    elif version == 's':\n",
    "        return 1/3, 1/2, 2.0\n",
    "    elif version == 'm':\n",
    "        return 2/3, 3/4, 1.5\n",
    "    elif version == 'l':\n",
    "        return 1.0, 1.0, 1.0\n",
    "    elif version == 'x':\n",
    "        return 1.0, 1.25, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Conv\n",
    "![Conv](images/conv.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0):\n",
      "Conv(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (act): SiLU(inplace=True)\n",
      ")\n",
      "torch.Size([1, 32, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "class Conv(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels (typically 3 for RGB images)\n",
    "    out_c: int, number of output channels (number of filters)\n",
    "    k: int, size of the kernel\n",
    "    s: int, stride of the kernel\n",
    "    p: int, padding of the kernel\n",
    "    g: int, number of groups\n",
    "    act: bool, whether to use activation function SiLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k = 3, s = 1, p = 1, g = 1, act = True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv2d: a convolutional layer\n",
    "        \"\"\"\n",
    "        in_c: int, number of input channels\n",
    "        out_c: int, number of output channels\n",
    "        k: int, size of the kernel\n",
    "        s: int, stride of the kernel\n",
    "        p: int, padding of the kernel\n",
    "        g: int, number of groups\n",
    "        bias: bool, whether to use bias\n",
    "        \"\"\"\n",
    "        self.conv = nn.Conv2d(in_c, out_c, k, s, p, bias = False, groups = g)\n",
    "\n",
    "        # BatchNorm2d: a normalization layer\n",
    "        \"\"\"\n",
    "        num_features: int, number of features\n",
    "        eps: float, a value added to the denominator for numerical stability\n",
    "        momentum: float, the value used for the running_mean and running_var computation\n",
    "        \"\"\"\n",
    "        self.bn = nn.BatchNorm2d(num_features = out_c, eps = 0.001, momentum = 0.03)\n",
    "\n",
    "        # SiLU: an activation function\n",
    "        \"\"\"\n",
    "        inplace: bool, whether to modify the input directly\n",
    "        \"\"\"\n",
    "        self.act = nn.SiLU(inplace = True) if act else nn.Identity()\n",
    "\n",
    "\n",
    "    # Conv2d -> BatchNorm2d -> SiLU\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Convolutional Layer)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(0):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 3\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    kernel size: 3\n",
    "    stride: 2\n",
    "    padding: 1\n",
    "    groups: 1\n",
    "    activation: True\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 3\n",
    "    image height: 640\n",
    "    image width: 640\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True)(torch.randn(1, 3, 640, 640)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bottleneck\n",
    "![Conv](images/bottleneck.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1):\n",
      "Bottleneck(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, shortcut=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = Conv(in_c, out_c, k = 3, s = 1, p = 1)\n",
    "        self.conv2 = Conv(out_c, out_c, k = 3, s = 1, p = 1)\n",
    "\n",
    "        # shortcut: a residual connection\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "\n",
    "    # Conv1 -> Conv2 -> Shortcut\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        if self.shortcut:\n",
    "            x = x + x_in\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Bottleneck in the First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(1):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    image height: 224\n",
    "    image width: 224\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True)(torch.randn(1, int(64*w), 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \"\"\"\n",
    "    scale_factor: int, scaling factor\n",
    "    mode: str, interpolation mode\n",
    "    \"\"\"\n",
    "    def __init__(self, scale_factor = 2, mode = 'nearest'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    # Upsample\n",
    "    def forward(self, x):\n",
    "        return nn.functional.interpolate(x, scale_factor = self.scale_factor, mode = self.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dfl):\n",
      "DFL(\n",
      "  (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "torch.Size([1, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "class DFL(nn.Module):\n",
    "    \"\"\"\n",
    "    ch: int, number of channels\n",
    "    \"\"\"\n",
    "    def __init__(self, ch = 16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ch = ch\n",
    "        \n",
    "        # Convolutional layer\n",
    "        self.conv = nn.Conv2d(in_channels = ch, out_channels = 1, kernel_size = 1, bias = False).requires_grad_(False)\n",
    "        \n",
    "        x = torch.arange(ch, dtype = torch.float).view(1, ch, 1, 1)\n",
    "        self.conv.weight.data[:] = torch.nn.Parameter(x)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, a = x.shape\n",
    "        x = x.view(b, 4, self.ch, a).transpose(1, 2)\n",
    "\n",
    "        # Softmax\n",
    "        x = x.softmax(1)\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x.view(b, 4, a)\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (DFL)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"(dfl):\")\n",
    "\n",
    "    \"\"\"\n",
    "    number of channels: 16\n",
    "    \"\"\"\n",
    "    print(DFL(ch = 16))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    number of channels: 16\n",
    "    \"\"\"\n",
    "    print(DFL(ch = 16)(torch.randn(1, 64, 128)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. C2f\n",
    "![C2f](images/c2f.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2):\n",
      "C2f(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): ModuleList(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 64, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "class C2f(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    num_bottlenecks: int, number of bottlenecks\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, num_bottlenecks, shortcut = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mid_channels = out_c // 2\n",
    "        self.num_bottlenecks = num_bottlenecks\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = Conv(in_c, out_c, k = 1, s = 1, p = 0)\n",
    "        self.conv2 = Conv((num_bottlenecks + 2) * out_c // 2, out_c, k = 1, s = 1, p = 0)\n",
    "        \n",
    "        # Bottleneck Sequence\n",
    "        self.m = nn.ModuleList([Bottleneck(self.mid_channels, self.mid_channels, shortcut) for _ in range(num_bottlenecks)])\n",
    "    \n",
    "\n",
    "    # Conv1 -> Split -> Bottleneck Sequence -> Concat -> Conv2\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x1, x2 = x[:,:x.shape[1]//2,:,:], x[:,x.shape[1]//2:,:,:]\n",
    "        outputs = [x1, x2]\n",
    "\n",
    "        for i in range(self.num_bottlenecks):\n",
    "            x1 = self.m[i](x1)\n",
    "            outputs.insert(0,x1)\n",
    "\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "\n",
    "        out = self.conv2(outputs)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(2):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 128 * width scaling factor (0.5)\n",
    "    output channels: 128 * width scaling factor (0.5)\n",
    "    number of bottlenecks: 3\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 128 * width scaling factor (0.5)\n",
    "    image height: 160\n",
    "    image width: 160\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True)(torch.randn(1, int(128*w), 160, 160)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SPPF\n",
    "![SPPF](images/sppf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9):\n",
      "SPPF(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "class SPPF(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    k: int, size of the kernel\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k = 5):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_c = in_c // 2\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = Conv(in_c, hidden_c, k = 1, s = 1, p = 0)\n",
    "        self.conv2 = Conv(4 * hidden_c, out_c, k = 1, s = 1, p = 0)\n",
    "\n",
    "        # MaxPool2d: a pooling layer\n",
    "        \"\"\"\n",
    "        k: int, size of the kernel\n",
    "        s: int, stride of the kernel\n",
    "        p: int, padding of the kernel\n",
    "        dilation: int, spacing between kernel elements\n",
    "        ceil_mode: bool, whether to use the ceil function to calculate the output size\n",
    "        \"\"\"\n",
    "        self.m = nn.MaxPool2d(kernel_size = k, stride = 1, padding = k // 2, dilation = 1, ceil_mode = False)\n",
    "    \n",
    "\n",
    "    # Conv1 -> MaxPool2ds -> Concat -> Conv2\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        y3 = self.m(y2)\n",
    "\n",
    "        y = torch.cat([x,y1,y2,y3], dim = 1)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (SPPF block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(9):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    output channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    kernel size: 5\n",
    "    \"\"\"\n",
    "    print(SPPF(in_c = int(512*w*r), out_c = int(512*w*r), k = 5))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    image height: 20\n",
    "    image width: 20\n",
    "    \"\"\"\n",
    "    print(SPPF(in_c = int(512*w*r), out_c = int(512*w*r), k = 5)(torch.randn(1, int(512*w*r), 20, 20)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Backbone\n",
    "![Backbone](images/backbone.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, version, in_c = 3, shortcut = True):\n",
    "        super().__init__()\n",
    "        d, w, r = params(version)\n",
    "\n",
    "        # Convolutional and C2f blocks\n",
    "        self.conv_0 = Conv(in_c, int(64*w), k = 3, s = 2, p = 1)\n",
    "        self.conv_1 = Conv(int(64*w), int(128*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_2 = C2f(int(128*w), int(128*w), num_bottlenecks = int(3*d), shortcut = True)\n",
    "        self.conv_3 = Conv(int(128*w), int(256*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_4 = C2f(int(256*w), int(256*w), num_bottlenecks = int(6*d), shortcut = True)\n",
    "        self.conv_5 = Conv(int(256*w), int(512*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_6 = C2f(int(512*w), int(512*w), num_bottlenecks = int(6*d), shortcut = True)\n",
    "        self.conv_7 = Conv(int(512*w), int(512*w*r), k = 3, s = 2, p = 1)\n",
    "        self.c2f_8 = C2f(int(512*w*r), int(512*w*r), num_bottlenecks = int(3*d), shortcut = True)\n",
    "\n",
    "        # SPPF block\n",
    "        self.sppf = SPPF(int(512*w*r), int(512*w*r))\n",
    "    \n",
    "\n",
    "    # Conv0 -> Conv1 -> C2f2 -> Conv3 -> C2f4 -> Conv5 -> C2f6 -> Conv7 -> C2f8 -> SPPF\n",
    "    def forward(self, x):\n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.c2f_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        out1 = self.c2f_4(x)\n",
    "        x = self.conv_5(out1)\n",
    "        out2 = self.c2f_6(x)\n",
    "        x = self.conv_7(out2)\n",
    "        x = self.c2f_8(x)\n",
    "        out3 = self.sppf(x)\n",
    "\n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone(\n",
      "  (conv_0): Conv(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv_1): Conv(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_2): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_3): Conv(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_4): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0-1): 2 x Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_5): Conv(\n",
      "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_6): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0-1): 2 x Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_7): Conv(\n",
      "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_8): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sppf): SPPF(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 128, 80, 80])\n",
      "torch.Size([1, 256, 40, 40])\n",
      "torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (Backbone)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    \"\"\"\n",
    "    version: s\n",
    "    input channels: 3\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(Backbone(version, in_c = 3, shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 3\n",
    "    image height: 640\n",
    "    image width: 640\n",
    "    \"\"\"\n",
    "    x = torch.randn(1, 3, 640, 640)\n",
    "    out1, out2, out3 = Backbone(version, in_c = 3, shortcut = True)(x)\n",
    "    print(out1.shape)\n",
    "    print(out2.shape)\n",
    "    print(out3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neck\n",
    "![Neck](images/neck.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(nn.Module):\n",
    "    \"\"\"\n",
    "    version: str, version of the model\n",
    "    \"\"\"\n",
    "    def __init__(self, version):\n",
    "        super().__init__()\n",
    "        d, w, r = params(version)\n",
    "\n",
    "        # Upsample block\n",
    "        self.up = Upsample()\n",
    "\n",
    "        # Convolutional and C2f blocks\n",
    "        self.c2f_1 = C2f(in_c = int(512*w*(1+r)),  out_c = int(512*w), num_bottlenecks = int(3*d), shortcut = False)\n",
    "        self.c2f_2 = C2f(in_c = int(768*w),  out_c = int(256*w), num_bottlenecks = int(3*d), shortcut = False)\n",
    "        self.conv_1 = Conv(in_c = int(256*w), out_c = int(256*w), k = 3, s = 2,  p = 1)\n",
    "        self.c2f_3 = C2f(in_c = int(768*w),  out_c = int(512*w), num_bottlenecks = int(3*d), shortcut = False)\n",
    "        self.conv_2 = Conv(in_c = int(512*w), out_c = int(512*w), k = 3, s = 2,  p = 1)\n",
    "        self.c2f_4 = C2f(in_c = int(512*w*(1+r)),  out_c = int(512*w*r), num_bottlenecks = int(3*d), shortcut = False)\n",
    "\n",
    "\n",
    "    # Upsample -> Concat -> C2f1 -> Upsample -> Concat -> C2f2 -> Upsample -> Concat -> C2f3 -> Upsample -> Concat -> C2f4\n",
    "    def forward(self, x_res_1, x_res_2, x):    \n",
    "        res_1 = x\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, x_res_2], dim = 1)\n",
    "        res_2 = self.c2f_1(x)\n",
    "        x = self.up(res_2)\n",
    "        x = torch.cat([x, x_res_1], dim = 1)\n",
    "        out_1 = self.c2f_2(x)\n",
    "        x = self.conv_1(out_1)\n",
    "        x = torch.cat([x, res_2], dim = 1)\n",
    "        out_2 = self.c2f_3(x)\n",
    "        x = self.conv_2(out_2)\n",
    "        x = torch.cat([x, res_1], dim = 1)\n",
    "        out_3 = self.c2f_4(x)\n",
    "\n",
    "        return out_1, out_2, out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neck(\n",
      "  (up): Upsample()\n",
      "  (c2f_1): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (c2f_2): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_1): Conv(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_3): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_2): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_4): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 128, 80, 80])\n",
      "torch.Size([1, 256, 40, 40])\n",
      "torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (Neck)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    \"\"\"\n",
    "    version: s\n",
    "    \"\"\"\n",
    "    print(Neck(version))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    image height: 40\n",
    "    image width: 40\n",
    "    \"\"\"\n",
    "    x = torch.rand((1,3,640,640))\n",
    "    out1, out2, out3 = Backbone(version = 's')(x)\n",
    "    out_1, out_2, out_3 = Neck(version = 's')(out1, out2, out3)\n",
    "    print(out_1.shape)\n",
    "    print(out_2.shape)\n",
    "    print(out_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Head\n",
    "![Head](images/head2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\"\n",
    "    version: str, version of the model\n",
    "    ch: int, number of channels\n",
    "    num_classes: int, number of classes\n",
    "    \"\"\"\n",
    "    def __init__(self, version, ch = 16, num_classes = 80):\n",
    "        super().__init__()\n",
    "        d, w, r = params(version = version)\n",
    "\n",
    "        self.ch = ch\n",
    "        self.coordinates = self.ch * 4\n",
    "        self.nc = num_classes\n",
    "        self.no = self.ch if version == 'x' else 0\n",
    "        self.stride = torch.zeros(3)\n",
    "\n",
    "        v = self.nc if version == 'n' else int(256*w)\n",
    "        \n",
    "        # Bounding Box\n",
    "        self.box = nn.ModuleList([\n",
    "            nn.Sequential(Conv(int(256*w), self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          Conv(self.coordinates + self.no, self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(self.coordinates + self.no, self.coordinates, kernel_size = 1, stride = 1)), \n",
    "\n",
    "            nn.Sequential(Conv(int(512*w), self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          Conv(self.coordinates + self.no, self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(self.coordinates + self.no, self.coordinates, kernel_size = 1, stride = 1)), \n",
    "\n",
    "            nn.Sequential(Conv(int(512*w*r), self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          Conv(self.coordinates + self.no, self.coordinates + self.no, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(self.coordinates + self.no, self.coordinates, kernel_size = 1, stride = 1))\n",
    "        ])\n",
    "\n",
    "        # Classification\n",
    "        self.cls = nn.ModuleList([\n",
    "            nn.Sequential(Conv(int(256*w), v, k = 3, s = 1, p = 1), \n",
    "                          Conv(v, v, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(v, self.nc, kernel_size = 1, stride = 1)), \n",
    "\n",
    "            nn.Sequential(Conv(int(512*w), v, k = 3, s = 1, p = 1), \n",
    "                          Conv(v, v, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(v, self.nc, kernel_size = 1, stride = 1)), \n",
    "\n",
    "            nn.Sequential(Conv(int(512*w*r), v, k = 3, s = 1, p = 1), \n",
    "                          Conv(v, v, k = 3, s = 1, p = 1), \n",
    "                          nn.Conv2d(v, self.nc, kernel_size = 1, stride = 1))\n",
    "        ])\n",
    "\n",
    "        # DFL\n",
    "        self.dfl = DFL()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.box)):\n",
    "            box = self.box[i](x[i])\n",
    "            cls = self.cls[i](x[i])\n",
    "            x[i] = torch.cat((box,cls),dim = 1)\n",
    "\n",
    "        if self.training:\n",
    "            return x\n",
    "        \n",
    "        anchors, ss = (i.transpose(0, 1) for i in self.make_anchors(x, self.s))\n",
    "\n",
    "        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], dim = 2)\n",
    "        \n",
    "        box, cls = x.split(split_size = (4 * self.ch, self.nc), dim = 1)\n",
    "\n",
    "        a, b = self.dfl(box).chunk(2, 1)\n",
    "        a = anchors.unsqueeze(0) - a\n",
    "        b = anchors.unsqueeze(0) + b\n",
    "        box = torch.cat(tensors = ((a + b) / 2, b - a), dim = 1)\n",
    "        \n",
    "        return torch.cat(tensors = (box * ss, cls.sigmoid()), dim = 1)\n",
    "\n",
    "\n",
    "    def make_anchors(self, x, ss, offset = 0.5):\n",
    "        assert x is not None\n",
    "        anchor_tensor, s_tensor = [],[]\n",
    "        dtype, device  =  x[0].dtype, x[0].device\n",
    "        for i, s in enumerate(ss):\n",
    "            _, _, h, w  =  x[i].shape\n",
    "            sx  =  torch.arange(end = w, device = device, dtype = dtype) + offset \n",
    "            sy  =  torch.arange(end = h, device = device, dtype = dtype) + offset\n",
    "            sy, sx  =  torch.meshgrid(sy, sx)\n",
    "            anchor_tensor.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
    "            s_tensor.append(torch.full((h * w, 1), s, dtype = dtype, device = device))\n",
    "\n",
    "        return torch.cat(anchor_tensor), torch.cat(s_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head(\n",
      "  (box): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (cls): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (dfl): DFL(\n",
      "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 144, 80, 80])\n",
      "torch.Size([1, 144, 40, 40])\n",
      "torch.Size([1, 144, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (Head)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    \"\"\"\n",
    "    version: s\n",
    "    number of channels: 16\n",
    "    number of classes: 80\n",
    "    \"\"\"\n",
    "    print(Head(version))\n",
    "\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    output = Head(version = 's')([out_1, out_2, out_3])\n",
    "    print(output[0].shape)\n",
    "    print(output[1].shape)\n",
    "    print(output[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.16656 million parameters\n",
      "Yolo(\n",
      "  (backbone): Backbone(\n",
      "    (conv_0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv_1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_2): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_4): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_6): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_8): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (sppf): SPPF(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (neck): Neck(\n",
      "    (up): Upsample()\n",
      "    (c2f_1): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (c2f_2): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_1): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_3): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_2): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_4): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Head(\n",
      "    (box): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (cls): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (dfl): DFL(\n",
      "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self,version):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = Backbone(version = version)\n",
    "        self.neck = Neck(version = version)\n",
    "        self.head = Head(version = version)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x[0], x[1], x[2])\n",
    "        return self.head(list(x))\n",
    "    \n",
    "model = Yolo(version = 's')\n",
    "print(f\"{sum(p.numel() for p in model.parameters())/1e6} million parameters\")\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
