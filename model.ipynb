{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return: depth scaling factor (d), width scaling factor (w), resolution scaling factor (r)\n",
    "\"\"\"\n",
    "def params(version):\n",
    "    if version == 'n':\n",
    "        return 1/3, 1/4, 2.0\n",
    "    elif version == 's':\n",
    "        return 1/3, 1/2, 2.0\n",
    "    elif version == 'm':\n",
    "        return 2/3, 3/4, 1.5\n",
    "    elif version == 'l':\n",
    "        return 1.0, 1.0, 1.0\n",
    "    elif version == 'x':\n",
    "        return 1.0, 1.25, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Conv\n",
    "![Conv](images/conv.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0):\n",
      "Conv(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (act): SiLU(inplace=True)\n",
      ")\n",
      "torch.Size([1, 32, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "class Conv(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels (typically 3 for RGB images)\n",
    "    out_c: int, number of output channels (number of filters)\n",
    "    k: int, size of the kernel\n",
    "    s: int, stride of the kernel\n",
    "    p: int, padding of the kernel\n",
    "    g: int, number of groups\n",
    "    act: bool, whether to use activation function SiLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k = 3, s = 1, p = 1, g = 1, act = True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv2d: a convolutional layer\n",
    "        \"\"\"\n",
    "        in_c: int, number of input channels\n",
    "        out_c: int, number of output channels\n",
    "        k: int, size of the kernel\n",
    "        s: int, stride of the kernel\n",
    "        p: int, padding of the kernel\n",
    "        g: int, number of groups\n",
    "        bias: bool, whether to use bias\n",
    "        \"\"\"\n",
    "        self.conv = nn.Conv2d(in_c, out_c, k, s, p, bias = False, groups = g)\n",
    "\n",
    "        # BatchNorm2d: a normalization layer\n",
    "        \"\"\"\n",
    "        num_features: int, number of features\n",
    "        eps: float, a value added to the denominator for numerical stability\n",
    "        momentum: float, the value used for the running_mean and running_var computation\n",
    "        \"\"\"\n",
    "        self.bn = nn.BatchNorm2d(num_features = out_c, eps = 0.001, momentum = 0.03)\n",
    "\n",
    "        # SiLU: an activation function\n",
    "        \"\"\"\n",
    "        inplace: bool, whether to modify the input directly\n",
    "        \"\"\"\n",
    "        self.act = nn.SiLU(inplace = True) if act else nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv2d -> BatchNorm2d -> SiLU\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Convolutional Layer)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(0):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 3\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    kernel size: 3\n",
    "    stride: 2\n",
    "    padding: 1\n",
    "    groups: 1\n",
    "    activation: True\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 3\n",
    "    image height: 640\n",
    "    image width: 640\n",
    "    \"\"\"\n",
    "    print(Conv(in_c = 3, out_c = int(64*w), k = 3, s = 2, p = 1, g = 1, act = True)(torch.randn(1, 3, 640, 640)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bottleneck\n",
    "![Conv](images/bottleneck.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1):\n",
      "Bottleneck(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, shortcut=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv1: first convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv1 = Conv(in_c, out_c, k = 3, s = 1, p = 1)\n",
    "\n",
    "        # Conv: second convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv2 = Conv(out_c, out_c, k = 3, s = 1, p = 1)\n",
    "\n",
    "        # shortcut: a residual connection\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "\n",
    "        # Conv1\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # Conv2\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Shortcut\n",
    "        if self.shortcut:\n",
    "            x = x + x_in\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First Bottleneck in the First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(1):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    output channels: 64 * width scaling factor (0.5)\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 64 * width scaling factor (0.5)\n",
    "    image height: 224\n",
    "    image width: 224\n",
    "    \"\"\"\n",
    "    print(Bottleneck(in_c = int(64*w), out_c = int(64*w), shortcut = True)(torch.randn(1, int(64*w), 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. C2f\n",
    "![C2f](images/c2f.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2):\n",
      "C2f(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): ModuleList(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 64, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "class C2f(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    num_bottlenecks: int, number of bottlenecks\n",
    "    shortcut: bool, whether to use a residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, num_bottlenecks, shortcut = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mid_channels = out_c // 2\n",
    "        self.num_bottlenecks = num_bottlenecks\n",
    "\n",
    "        # Conv1: first convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv1 = Conv(in_c, out_c, k = 1, s = 1, p = 0)\n",
    "        \n",
    "        # Bottleneck Sequence\n",
    "        self.m = nn.ModuleList([Bottleneck(self.mid_channels, self.mid_channels, shortcut) for _ in range(num_bottlenecks)])\n",
    "\n",
    "        # Conv2: second convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv2 = Conv((num_bottlenecks + 2) * out_c // 2, out_c, k = 1, s = 1, p = 0)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        # Conv1\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # Split\n",
    "        x1, x2 = x[:,:x.shape[1]//2,:,:], x[:,x.shape[1]//2:,:,:]\n",
    "        outputs = [x1, x2]\n",
    "\n",
    "        # Bottleneck Sequence\n",
    "        for i in range(self.num_bottlenecks):\n",
    "            x1 = self.m[i](x1)\n",
    "            outputs.insert(0,x1)\n",
    "\n",
    "        # Concat\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "\n",
    "        # Conv2\n",
    "        out = self.conv2(outputs)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (First C2f block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(2):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 128 * width scaling factor (0.5)\n",
    "    output channels: 128 * width scaling factor (0.5)\n",
    "    number of bottlenecks: 3\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 128 * width scaling factor (0.5)\n",
    "    image height: 160\n",
    "    image width: 160\n",
    "    \"\"\"\n",
    "    print(C2f(in_c = int(128*w), out_c = int(128*w), num_bottlenecks = 1, shortcut = True)(torch.randn(1, int(128*w), 160, 160)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SPPF\n",
    "![SPPF](images/sppf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9):\n",
      "SPPF(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "class SPPF(nn.Module):\n",
    "    \"\"\"\n",
    "    in_c: int, number of input channels\n",
    "    out_c: int, number of output channels\n",
    "    k: int, size of the kernel\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k = 5):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_c = in_c // 2\n",
    "\n",
    "        # Conv1: first convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv1 = Conv(in_c, hidden_c, k = 1, s = 1, p = 0)\n",
    "\n",
    "        # Conv2: second convolutional layer\n",
    "        \"\"\"\n",
    "        Explanation can be seen in the Conv class above\n",
    "        \"\"\"\n",
    "        self.conv2 = Conv(4 * hidden_c, out_c, k = 1, s = 1, p = 0)\n",
    "\n",
    "        # MaxPool2d: a pooling layer\n",
    "        \"\"\"\n",
    "        k: int, size of the kernel\n",
    "        s: int, stride of the kernel\n",
    "        p: int, padding of the kernel\n",
    "        dilation: int, spacing between kernel elements\n",
    "        ceil_mode: bool, whether to use the ceil function to calculate the output size\n",
    "        \"\"\"\n",
    "        self.m = nn.MaxPool2d(kernel_size = k, stride = 1, padding = k // 2, dilation = 1, ceil_mode = False)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        # Conv1\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # MaxPool2ds\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        y3 = self.m(y2)\n",
    "\n",
    "        # Concat\n",
    "        y = torch.cat([x,y1,y2,y3], dim = 1)\n",
    "\n",
    "        # Conv2\n",
    "        y = self.conv2(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "\n",
    "\n",
    "# Sanity check (SPPF block)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    print(\"(9):\")\n",
    "\n",
    "    \"\"\"\n",
    "    input channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    output channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    kernel size: 5\n",
    "    \"\"\"\n",
    "    print(SPPF(in_c = int(512*w*r), out_c = int(512*w*r), k = 5))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 512 * width scaling factor (0.5) * resolution scaling factor (2.0)\n",
    "    image height: 20\n",
    "    image width: 20\n",
    "    \"\"\"\n",
    "    print(SPPF(in_c = int(512*w*r), out_c = int(512*w*r), k = 5)(torch.randn(1, int(512*w*r), 20, 20)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Backbone\n",
    "![Backbone](images/backbone.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, version, in_c = 3, shortcut = True):\n",
    "        super().__init__()\n",
    "        d, w, r = params(version)\n",
    "\n",
    "        # Convolutional and C2f blocks\n",
    "        self.conv_0 = Conv(in_c, int(64*w), k = 3, s = 2, p = 1)\n",
    "        self.conv_1 = Conv(int(64*w), int(128*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_2 = C2f(int(128*w), int(128*w), num_bottlenecks = int(3*d), shortcut = True)\n",
    "        self.conv_3 = Conv(int(128*w), int(256*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_4 = C2f(int(256*w), int(256*w), num_bottlenecks = int(6*d), shortcut = True)\n",
    "        self.conv_5 = Conv(int(256*w), int(512*w), k = 3, s = 2, p = 1)\n",
    "        self.c2f_6 = C2f(int(512*w), int(512*w), num_bottlenecks = int(6*d), shortcut = True)\n",
    "        self.conv_7 = Conv(int(512*w), int(512*w*r), k = 3, s = 2, p = 1)\n",
    "        self.c2f_8 = C2f(int(512*w*r), int(512*w*r), num_bottlenecks = int(3*d), shortcut = True)\n",
    "\n",
    "        # SPPF block\n",
    "        self.sppf = SPPF(int(512*w*r), int(512*w*r))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional and C2f blocks\n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.c2f_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        out1 = self.c2f_4(x)\n",
    "        x = self.conv_5(out1)\n",
    "        out2 = self.c2f_6(x)\n",
    "        x = self.conv_7(out2)\n",
    "        x = self.c2f_8(x)\n",
    "        out3 = self.sppf(x)\n",
    "\n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone(\n",
      "  (conv_0): Conv(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (conv_1): Conv(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_2): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_3): Conv(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_4): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0-1): 2 x Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_5): Conv(\n",
      "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_6): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0-1): 2 x Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_7): Conv(\n",
      "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (c2f_8): C2f(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): ModuleList(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (sppf): SPPF(\n",
      "    (conv1): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Conv(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 128, 80, 80])\n",
      "torch.Size([1, 256, 40, 40])\n",
      "torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (Backbone)\n",
    "if __name__ == \"__main__\":\n",
    "    version = 's'\n",
    "    d, w, r = params(version)\n",
    "\n",
    "    \"\"\"\n",
    "    version: s\n",
    "    input channels: 3\n",
    "    shortcut: True\n",
    "    \"\"\"\n",
    "    print(Backbone(version, in_c = 3, shortcut = True))\n",
    "\n",
    "    \"\"\"\n",
    "    batch size: 1\n",
    "    input channels: 3\n",
    "    image height: 640\n",
    "    image width: 640\n",
    "    \"\"\"\n",
    "    print(Backbone(version, in_c = 3, shortcut = True)(torch.randn(1, 3, 640, 640))[0].shape)\n",
    "    print(Backbone(version, in_c = 3, shortcut = True)(torch.randn(1, 3, 640, 640))[1].shape)\n",
    "    print(Backbone(version, in_c = 3, shortcut = True)(torch.randn(1, 3, 640, 640))[2].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
